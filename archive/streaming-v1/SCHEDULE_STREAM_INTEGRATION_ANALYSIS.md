# Schedule Calculator Stream Integration Analysis

## Executive Summary

The Tributestream schedule calculator currently has **critical data flow issues** that create duplicate streams, inconsistent data, and poor user experience. This analysis covers risks, solutions, API routes, interfaces, and database collections involved in the schedule-to-stream integration.

---

## ðŸš¨ Critical Risks Identified

### 1. **Data Integrity Risks**
- **Duplicate Stream Creation**: Every save operation creates new streams instead of updating existing ones
- **Orphaned Streams**: Removing services doesn't delete associated streams
- **Inconsistent Data**: Streams don't reflect current service information after updates
- **Auto-save Conflicts**: Stream creation triggered every 2 seconds during form editing

### 2. **Performance & Cost Risks**
- **Cloudflare API Abuse**: Excessive live input creation (every auto-save)
- **Database Pollution**: Multiple duplicate streams per memorial
- **API Rate Limiting**: Potential Cloudflare API throttling
- **Storage Costs**: Unnecessary stream storage and bandwidth usage

### 3. **User Experience Risks**
- **Confusion**: Multiple identical streams in stream manager
- **Broken Workflows**: Streams not reflecting schedule changes
- **Lost Data**: No way to update existing stream details
- **Performance Issues**: Slow page loads due to excessive API calls

### 4. **Business Logic Risks**
- **Revenue Impact**: Incorrect billing due to duplicate streams
- **Support Burden**: Users confused by multiple streams
- **Data Compliance**: Orphaned data not properly cleaned up
- **Scaling Issues**: System won't scale with current architecture

---

## ðŸ—ï¸ Current Architecture

### Data Flow Diagram
```
User Input â†’ Schedule Form â†’ Auto-save (2s) â†’ Memorial.services â†’ Stream Creation
                                    â†“
                            createStreamsFromSchedule()
                                    â†“
                            POST /api/memorials/[id]/streams
                                    â†“
                            Cloudflare Live Input Creation
                                    â†“
                            Stream Document in Firestore
```

### Key Components
1. **Schedule Calculator** (`/schedule/[memorialId]`)
2. **Auto-save Composable** (`useAutoSave.ts`)
3. **Stream Mapper** (`streamMapper.ts`)
4. **Stream API** (`/api/memorials/[memorialId]/streams`)
5. **Cloudflare Integration** (`cloudflare-stream.ts`)

---

## ðŸ“Š Database Collections

### 1. **Memorials Collection**
```typescript
interface Memorial {
  id: string;
  lovedOneName: string;
  ownerUid: string;
  funeralDirectorUid?: string;
  
  // Service scheduling data
  services: {
    main: ServiceDetails;
    additional: AdditionalServiceDetails[];
  };
  
  // Calculator configuration
  calculatorConfig?: {
    formData: CalculatorFormData;
    autoSave: AutoSaveData;
    status: 'draft' | 'saved' | 'pending_payment' | 'paid';
  };
  
  // Metadata
  createdAt: Timestamp;
  updatedAt: Timestamp;
  lastModifiedBy: string;
}
```

### 2. **Streams Collection**
```typescript
interface Stream {
  id: string;
  title: string;
  description?: string;
  memorialId: string;
  status: 'scheduled' | 'ready' | 'live' | 'completed' | 'error';
  
  // Cloudflare integration
  cloudflareInputId?: string;
  streamKey?: string;
  rtmpUrl?: string;
  
  // Scheduling
  scheduledStartTime?: string;
  
  // Calculator linking (CRITICAL MISSING FEATURE)
  calculatorServiceType?: 'main' | 'location' | 'day';
  calculatorServiceIndex?: number | null;
  
  // Metadata
  createdBy: string;
  createdAt: string;
  updatedAt: string;
}
```

### 3. **Missing Collections/Fields**
- **Stream-Service Relationships**: No bidirectional linking
- **Stream History**: No audit trail for stream changes
- **Orphaned Stream Cleanup**: No mechanism to identify unused streams

---

## ðŸ”Œ API Routes Analysis

### 1. **Stream Management APIs**

#### `GET /api/memorials/[memorialId]/streams`
- **Purpose**: Fetch all streams for a memorial
- **Issues**: No filtering by calculator service type
- **Missing**: Stream-service relationship data

#### `POST /api/memorials/[memorialId]/streams`
- **Purpose**: Create new stream
- **Issues**: No duplicate detection, no update logic
- **Missing**: Stream synchronization with existing services

#### `PUT /api/memorials/[memorialId]/streams/[streamId]` âŒ **MISSING**
- **Needed**: Update existing stream details
- **Use Case**: Sync stream with updated service information

#### `DELETE /api/memorials/[memorialId]/streams/[streamId]` âŒ **MISSING**
- **Needed**: Delete orphaned streams
- **Use Case**: Remove streams when services are deleted

### 2. **Schedule Management APIs**

#### `POST /api/memorials/[memorialId]/schedule/auto-save`
- **Purpose**: Auto-save schedule data
- **Issues**: Triggers stream creation on every save
- **Solution**: Separate data saving from stream operations

#### `GET /api/memorials/[memorialId]/schedule/auto-save`
- **Purpose**: Load auto-saved schedule data
- **Status**: âœ… Working correctly

### 3. **Missing APIs**

#### `POST /api/memorials/[memorialId]/streams/sync` âŒ **NEEDED**
- **Purpose**: Synchronize streams with current schedule
- **Logic**: Create, update, or delete streams based on services

#### `GET /api/memorials/[memorialId]/streams/by-service` âŒ **NEEDED**
- **Purpose**: Get streams filtered by calculator service
- **Use Case**: Find existing streams for specific services

---

## ðŸ”§ TypeScript Interfaces

### 1. **Current Interfaces**

#### ServiceDetails Interface
```typescript
interface ServiceDetails {
  location: LocationInfo;
  time: TimeInfo;
  hours: number;
  streamId?: string; // âŒ MISSING - needed for linking
}

interface LocationInfo {
  name: string;
  address: string;
  isUnknown: boolean;
}

interface TimeInfo {
  date: string | null;
  time: string | null;
  isUnknown: boolean;
}
```

#### Stream Interface (Enhanced)
```typescript
interface Stream {
  // ... existing fields ...
  
  // Calculator integration (partially implemented)
  calculatorServiceType?: 'main' | 'location' | 'day';
  calculatorServiceIndex?: number | null;
  
  // âŒ MISSING FIELDS NEEDED:
  serviceHash?: string; // Hash of service data for change detection
  lastSyncedAt?: string; // When stream was last synced with service
  syncStatus?: 'synced' | 'outdated' | 'orphaned';
}
```

### 2. **New Interfaces Needed**

#### Stream Synchronization
```typescript
interface StreamSyncRequest {
  memorialId: string;
  services: {
    main: ServiceDetails;
    additional: AdditionalServiceDetails[];
  };
  forceSync?: boolean;
}

interface StreamSyncResult {
  success: boolean;
  operations: {
    created: Stream[];
    updated: Stream[];
    deleted: string[];
  };
  errors: string[];
}
```

#### Service-Stream Mapping
```typescript
interface ServiceStreamMapping {
  serviceType: 'main' | 'location' | 'day';
  serviceIndex: number | null;
  serviceHash: string;
  streamId: string;
  lastSynced: string;
}
```

---

## ðŸ’¡ Recommended Solutions

### Phase 1: Immediate Fixes (Critical)

#### 1. **Disable Auto-save Stream Creation**
```typescript
// In schedule page - remove stream creation from auto-save
await autoSave.saveNow({
  services: updatedServices,
  calculatorData: calculatorData
  // âŒ Remove: createStreamsFromSchedule()
});
```

#### 2. **Add Duplicate Detection**
```typescript
// Before creating streams, check for existing ones
const existingStreams = await fetch(`/api/memorials/${memorialId}/streams`);
const duplicates = findDuplicateStreams(streamRequests, existingStreams);
```

#### 3. **Implement Stream Update API**
```typescript
// PUT /api/memorials/[memorialId]/streams/[streamId]
export const PUT: RequestHandler = async ({ params, request }) => {
  const { title, description, scheduledStartTime } = await request.json();
  
  // Update stream in Firestore
  await adminDb.collection('streams').doc(params.streamId).update({
    title, description, scheduledStartTime,
    updatedAt: new Date().toISOString()
  });
};
```

### Phase 2: Stream Synchronization (Medium Priority)

#### 1. **Service-Stream Linking**
```typescript
// Add streamId to service data
interface ServiceDetails {
  location: LocationInfo;
  time: TimeInfo;
  hours: number;
  streamId?: string; // Link to associated stream
  streamHash?: string; // Hash for change detection
}
```

#### 2. **Stream Sync API**
```typescript
// POST /api/memorials/[memorialId]/streams/sync
export const POST: RequestHandler = async ({ params, request }) => {
  const { services } = await request.json();
  
  // Get existing streams
  const existingStreams = await getStreamsByMemorial(params.memorialId);
  
  // Sync logic
  const result = await syncStreamsWithServices(services, existingStreams);
  
  return json(result);
};
```

#### 3. **Change Detection**
```typescript
function generateServiceHash(service: ServiceDetails): string {
  return crypto
    .createHash('md5')
    .update(JSON.stringify({
      location: service.location,
      time: service.time,
      hours: service.hours
    }))
    .digest('hex');
}
```

### Phase 3: Advanced Features (Low Priority)

#### 1. **Stream History & Audit**
```typescript
interface StreamHistory {
  streamId: string;
  action: 'created' | 'updated' | 'deleted';
  changes: Record<string, any>;
  timestamp: string;
  userId: string;
}
```

#### 2. **Batch Operations**
```typescript
interface BatchStreamOperation {
  operations: Array<{
    type: 'create' | 'update' | 'delete';
    streamId?: string;
    data?: Partial<Stream>;
  }>;
}
```

#### 3. **Real-time Sync**
```typescript
// WebSocket or Server-Sent Events for real-time updates
const streamUpdates = new EventSource(`/api/memorials/${memorialId}/streams/events`);
```

---

## ðŸŽ¯ Implementation Priority

### ðŸ”´ **Critical (Immediate)**
1. Disable stream creation in auto-save
2. Add duplicate detection to stream creation
3. Implement stream update API
4. Add service-stream linking fields

### ðŸŸ¡ **High (Within 1 week)**
1. Create stream synchronization API
2. Implement change detection logic
3. Add orphaned stream cleanup
4. Update UI to show stream-service relationships

### ðŸŸ¢ **Medium (Within 1 month)**
1. Add stream history/audit trail
2. Implement batch operations
3. Create stream management dashboard
4. Add automated testing

### ðŸ”µ **Low (Future)**
1. Real-time synchronization
2. Advanced analytics
3. Stream templates
4. Automated stream optimization

---

## ðŸ§ª Testing Strategy

### Unit Tests Needed
```typescript
describe('Stream Synchronization', () => {
  test('should update existing stream when service changes');
  test('should create new stream for new service');
  test('should delete orphaned streams');
  test('should detect service changes via hash');
});
```

### Integration Tests Needed
```typescript
describe('Schedule-Stream Integration', () => {
  test('should sync streams on manual save');
  test('should not create streams on auto-save');
  test('should handle concurrent updates');
  test('should maintain data consistency');
});
```

### End-to-End Tests Needed
- Complete schedule creation flow
- Stream management workflows
- Error handling scenarios
- Performance under load

---

## ðŸ“ˆ Success Metrics

### Technical Metrics
- **Stream Duplication Rate**: Target < 1%
- **API Response Time**: Target < 500ms
- **Data Consistency**: Target 99.9%
- **Error Rate**: Target < 0.1%

### User Experience Metrics
- **Schedule Completion Rate**: Target > 95%
- **Stream Management Satisfaction**: Target > 4.5/5
- **Support Tickets**: Target < 5% of current volume
- **User Retention**: Target > 90%

### Business Metrics
- **Cloudflare API Costs**: Target 50% reduction
- **Database Storage**: Target 30% reduction
- **Development Velocity**: Target 25% improvement
- **Customer Satisfaction**: Target > 4.7/5

---

## ðŸš€ Conclusion

The current schedule-stream integration has fundamental architectural issues that require immediate attention. The recommended phased approach will:

1. **Immediately** stop data corruption and duplicate creation
2. **Quickly** implement proper synchronization logic
3. **Eventually** provide advanced stream management features

**Estimated Timeline**: 2-3 weeks for critical fixes, 1-2 months for complete solution.

**Resource Requirements**: 1 senior developer, 1 QA engineer, DevOps support for deployment.

**Risk Mitigation**: Implement feature flags, gradual rollout, comprehensive testing, and rollback procedures.
